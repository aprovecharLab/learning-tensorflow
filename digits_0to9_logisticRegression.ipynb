{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: classify digits 0-9 using logistic regression using one-hot encoding of classes and softmax activation\n",
    "\n",
    "### with help from:\n",
    "* https://www.coursera.org/specializations/deep-learning homework\n",
    "* https://liufuyang.github.io/2017/03/17/just-another-tensorflow-beginner-guide-2.html examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use skikits learn helper function to split data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bar and loop timing\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to read mnist data files\n",
    "# from: https://github.com/zalandoresearch/fashion-mnist\n",
    "import mnist_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset everything\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1)\n",
    "seed = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    (Check: will only work with flattened images because of indexing?)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \n",
    "    from Andrew Ng - Coursera Deep Learning Specialization,\n",
    "        https://www.coursera.org/specializations/deep-learning\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :]\n",
    "    shuffled_Y = Y[permutation, :]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m, :]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \n",
    "    from Andrew Ng - Coursera Deep Learning Specialization,\n",
    "        https://www.coursera.org/specializations/deep-learning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'.\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "    \n",
    "    # Create and run the session\n",
    "    with tf.Session() as sess:\n",
    "        one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from post: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def shuffle_in_unison(X, y):\n",
    "    shuffled_X = np.empty(X.shape, dtype=X.dtype)\n",
    "    shuffled_y = np.empty(y.shape, dtype=y.dtype)\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_X[new_index,:,:] = X[old_index,:,:]\n",
    "        shuffled_y[new_index,:] = y[old_index,:]\n",
    "    return shuffled_X, shuffled_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these examples are gray scale images\n",
    "# nc = 1\n",
    "# and are for 10 classes with one-hot encoding\n",
    "n_classes = 10\n",
    "\n",
    "# try this dataset\n",
    "###############################################################\n",
    "# ASL hand sign digits 0-9\n",
    "# Turkey Ankara AyrancÄ± Anadolu High School's Sign Language Digits Dataset\n",
    "# https://github.com/ardamavi/Sign-Language-Digits-Dataset\n",
    "# converted to npy files by modifying this code: gist.github.com/ardamavi/get_dataset.py\n",
    "\n",
    "# X_data = np.load('data/ASL-digits/ASL_X.npy').astype(np.float32)\n",
    "# y_data = np.load('data/ASL-digits/ASL_Y.npy').astype(np.float32)\n",
    "# y_data = one_hot_matrix(y_data,C=n_classes).T\n",
    "\n",
    "# X_data, y_data = shuffle_in_unison(X_data,y_data) # this dataset is ordered, so must shuffle\n",
    "# m,nh,nw = X_data.shape\n",
    "\n",
    "# or this dataset\n",
    "###############################################################\n",
    "# MNIST handwritten digits 0-9: \"Gradient-based learning applied to document recognition.\"\n",
    "#   Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.    \n",
    "#   Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
    "#   http://yann.lecun.com/exdb/mnist/\n",
    "#\n",
    "#   we are using only the train set here, and splitting it to train/test sets separately\n",
    "# X_data, y_data = mnist_reader.load_mnist('data/mnist-digits', kind='train')\n",
    "\n",
    "# or this dataset\n",
    "###############################################################\n",
    "# Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning \n",
    "#   Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "#   https://github.com/zalandoresearch/fashion-mnist\n",
    "#\n",
    "#   we are using only the train set here, and splitting it to train/test sets separately\n",
    "X_data, y_data = mnist_reader.load_mnist('data/mnist-fashion', kind='train')\n",
    "\n",
    "\n",
    "# must normalize the data and convert labels to one-hot representation\n",
    "X_data = X_data / 255.0\n",
    "y_data = one_hot_matrix(y_data,C=n_classes).T\n",
    "\n",
    "m,hxw = X_data.shape\n",
    "nh = np.int(np.sqrt(hxw))\n",
    "nw = np.int(np.sqrt(hxw))\n",
    "X_data = np.reshape(X_data,(m,nh,nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (X_data.shape)\n",
    "print (y_data.shape)\n",
    "# print (hxw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take a look at one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd08b2a208>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_data[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (y_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into test / train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40200, 28, 28) (40200, 10)\n",
      "(19800, 28, 28) (19800, 10)\n"
     ]
    }
   ],
   "source": [
    "# just to practice, split into train/test sets ourselves\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,y_data, test_size=0.33, \n",
    "                                                    shuffle=True, random_state = 42)\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use tensorflow index notation and flatten 2-D images to 1-D features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40200, 784) (40200, 10)\n",
      "(19800, 784) (19800, 10)\n"
     ]
    }
   ],
   "source": [
    "# many data sets use X[m,nh,nw,nc] and tesnsorflow and scikits learn use m as first index\n",
    "# keep this convention\n",
    "\n",
    "# X_data = X_data.reshape(m,nh,nw,1)\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data input and formatted properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a simple application of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants, variables, placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, nh*nw], name = 'X')\n",
    "print (str(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Y:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, n_classes], name = 'Y')\n",
    "print (str(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'W:0' shape=(784, 10) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.ones([nh*nw, n_classes]), name = 'W')\n",
    "print (str(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'b:0' shape=(1, 10) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "b = tf.Variable(tf.zeros([1, n_classes]), name = 'b')\n",
    "print (str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define computation graph: simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "z = tf.add(tf.matmul(X,W),b)\n",
    "y = tf.nn.softmax(z)\n",
    "\n",
    "# instead do this if we use \"softmax_cross_entropy\" function for cost below\n",
    "# y = tf.add(tf.matmul(X,W),b)\n",
    "\n",
    "print (str(z))\n",
    "print (str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y_true*tf.log(y)))\n",
    "\n",
    "# here must transpose to tensorflow softmax_cross_entropy_with_logits requirements\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.transpose(y_true), \\\n",
    "#                                                                  logits=tf.transpose(y)))\n",
    "\n",
    "print (str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))   \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mini_batches:  628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3587ff12a7e7411b9c1ef6d1e4acb1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', style=ProgressStyle(description_width='initial')), HTâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Accuracy: 0.8525757789611816\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    batch_count = np.int(num_examples/batch_size)\n",
    "    print ('number of mini_batches: ',batch_count)\n",
    "\n",
    "    for epoch in tnrange(training_epochs, desc='epoch'):\n",
    "        \n",
    "        seed = seed+1\n",
    "        mini_batches = random_mini_batches(X_train, y_train, batch_size, seed=seed)\n",
    "        \n",
    "        for mini_batch in mini_batches:\n",
    "\n",
    "            (batch_x, batch_y) = mini_batch\n",
    "\n",
    "            _, c = sess.run([train,cost],feed_dict = {X:batch_x, y_true:batch_y})\n",
    "#             print(c)\n",
    "\n",
    "    print('Final Test Set Accuracy: {}'.format(accuracy.eval(feed_dict={X:X_test, y_true:y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this again, but format and write a log file for TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start up tensorboard with \n",
    "$ tensorboard --logdir=./tmp/example --port=8002 --reload_interval=5\n",
    "\n",
    "open browser at http://localhost:8002/ \n",
    "then you should be able to see the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard log file path\n",
    "logs_path = './tmp/example1/'+datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset everything\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1)\n",
    "seed = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow constants, variables, placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, nh*nw])\n",
    "    y_true = tf.placeholder(tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('weights'):\n",
    "    W = tf.Variable(tf.ones([nh*nw, n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('biases'):\n",
    "    b = tf.Variable(tf.zeros([1, n_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define computation graph: simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('softmax'):\n",
    "    z = tf.add(tf.matmul(X,W),b)\n",
    "    y = tf.nn.softmax(z)\n",
    "    \n",
    "# instead do this if we use \"softmax_cross_entropy\" function for cost below\n",
    "# with tf.name_scope('softmax'):\n",
    "#     y = tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y)))\n",
    "\n",
    "# with tf.name_scope('cross_entropy'):\n",
    "#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.transpose(y_true), \\\n",
    "#                                                                      logits=tf.transpose(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_predictions = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))   \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for tensorboard\n",
    "train_cost_summary = tf.summary.scalar(\"train_cost\", cost)\n",
    "train_accuracy_summary = tf.summary.scalar(\"train_accuracy\", accuracy)\n",
    "\n",
    "test_cost_summary = tf.summary.scalar(\"test_cost\", cost)\n",
    "test_accuracy_summary = tf.summary.scalar(\"test_accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mini_batches:  628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618be09eb2504bc2995072b9c0de4299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', style=ProgressStyle(description_width='initial')), HTâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Accuracy: 0.8525757789611816\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # tensorboard log file writer    \n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    batch_count = np.int(num_examples/batch_size)\n",
    "    print ('number of mini_batches: ',batch_count)\n",
    "\n",
    "    for epoch in tnrange(training_epochs, desc='epoch'):\n",
    "        \n",
    "        seed = seed+1\n",
    "        mini_batches = random_mini_batches(X_train, y_train, batch_size, seed=seed)\n",
    "        \n",
    "        iter = 0        \n",
    "        for mini_batch in mini_batches:\n",
    "            \n",
    "            iter = iter+1\n",
    "\n",
    "            (batch_x, batch_y) = mini_batch\n",
    "            \n",
    "            _, train_cost, train_accuracy, _train_cost_summary, _train_accuracy_summary = \\\n",
    "               sess.run([train, cost, accuracy, train_cost_summary, train_accuracy_summary], \\\n",
    "                   feed_dict={X: batch_x, y_true: batch_y})\n",
    "            \n",
    "            writer.add_summary(_train_cost_summary, epoch * batch_count + iter)\n",
    "            writer.add_summary(_train_accuracy_summary, epoch * batch_count + iter)\n",
    "       \n",
    "            if iter % 100 == 0:\n",
    "                # for log on test data:\n",
    "                test_cost, test_accuracy, _test_cost_summary, _test_accuracy_summary = \\\n",
    "                    sess.run([cost, accuracy, test_cost_summary, test_accuracy_summary], \\\n",
    "                        feed_dict={X:X_test, y_true:y_test})\n",
    "                # write log\n",
    "                writer.add_summary(_test_cost_summary, epoch * batch_count + iter)\n",
    "                writer.add_summary(_test_accuracy_summary, epoch * batch_count + iter)\n",
    "                \n",
    "#                 print('Epoch {0:3d}, Batch {1:3d} | Train Cost: {2:.2f} | Test Cost: {3:.2f} | Train Accuracy: {4:.2f} | Test Accuracy: {5:.2f}'.format(epoch, iter, train_cost, test_cost, train_accuracy, test_accuracy))\n",
    "            \n",
    "    print('Final Test Set Accuracy: {}'.format(accuracy.eval(feed_dict={X:X_test, y_true:y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
