{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: classify digits 0-9 using CNN followed by fully-connected layer using one-hot encoding of classes and softmax activation\n",
    "\n",
    "### with help from:\n",
    "* https://www.coursera.org/specializations/deep-learning homework\n",
    "* https://liufuyang.github.io/2017/03/17/just-another-tensorflow-beginner-guide-2.html examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use skikits learn helper function to split data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bar and loop timing\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to read mnist data files\n",
    "# from: https://github.com/zalandoresearch/fashion-mnist\n",
    "import mnist_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset everything\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1)\n",
    "seed = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches_img(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \n",
    "    from Andrew Ng - Coursera Deep Learning Specialization,\n",
    "        https://www.coursera.org/specializations/deep-learning\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \n",
    "    from Andrew Ng - Coursera Deep Learning Specialization,\n",
    "        https://www.coursera.org/specializations/deep-learning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'.\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "    \n",
    "    # Create and run the session\n",
    "    with tf.Session() as sess:\n",
    "        one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from post: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "def shuffle_in_unison(X, y):\n",
    "    shuffled_X = np.empty(X.shape, dtype=X.dtype)\n",
    "    shuffled_y = np.empty(y.shape, dtype=y.dtype)\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_X[new_index,:,:] = X[old_index,:,:]\n",
    "        shuffled_y[new_index,:] = y[old_index,:]\n",
    "    return shuffled_X, shuffled_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these examples are gray scale images\n",
    "nc = 1\n",
    "# and are for 10 classes with one-hot encoding\n",
    "n_classes = 10\n",
    "\n",
    "# try this dataset\n",
    "###############################################################\n",
    "# ASL hand sign digits 0-9\n",
    "# Turkey Ankara AyrancÄ± Anadolu High School's Sign Language Digits Dataset\n",
    "# https://github.com/ardamavi/Sign-Language-Digits-Dataset\n",
    "# converted to npy files by modifying this code: gist.github.com/ardamavi/get_dataset.py\n",
    "\n",
    "# X_data = np.load('data/ASL-digits/ASL_X.npy').astype(np.float32)\n",
    "# y_data = np.load('data/ASL-digits/ASL_Y.npy').astype(np.float32)\n",
    "# y_data = one_hot_matrix(y_data,C=n_classes).T\n",
    "\n",
    "# X_data, y_data = shuffle_in_unison(X_data,y_data) # this dataset is ordered, so must shuffle\n",
    "# m,nh,nw = X_data.shape\n",
    "\n",
    "# or this dataset\n",
    "###############################################################\n",
    "# MNIST handwritten digits 0-9: \"Gradient-based learning applied to document recognition.\"\n",
    "#   Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.    \n",
    "#   Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
    "#   http://yann.lecun.com/exdb/mnist/\n",
    "#\n",
    "#   we are using only the train set here, and splitting it to train/test sets separately\n",
    "# X_data, y_data = mnist_reader.load_mnist('data/mnist-digits', kind='train')\n",
    "\n",
    "# or this dataset\n",
    "###############################################################\n",
    "# Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning \n",
    "#   Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "#   https://github.com/zalandoresearch/fashion-mnist\n",
    "#\n",
    "#   we are using only the train set here, and splitting it to train/test sets separately\n",
    "X_data, y_data = mnist_reader.load_mnist('data/mnist-fashion', kind='train')\n",
    "\n",
    "\n",
    "# must normalize the data and convert labels to one-hot representation\n",
    "X_data = X_data / 255.0\n",
    "y_data = one_hot_matrix(y_data,C=n_classes).T\n",
    "\n",
    "m,hxw = X_data.shape\n",
    "nh = np.int(np.sqrt(hxw))\n",
    "nw = np.int(np.sqrt(hxw))\n",
    "X_data = np.reshape(X_data,(m,nh,nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (X_data.shape)\n",
    "print (y_data.shape)\n",
    "\n",
    "# grayscale = one color channel\n",
    "X_data = X_data.reshape(m,nh,nw,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take a look at one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8de72bf2b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_data[300,:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (y_data[300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into test / train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40200, 28, 28, 1) (40200, 10)\n",
      "(19800, 28, 28, 1) (19800, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data,y_data, test_size=0.33, \n",
    "                                                    shuffle=True, random_state = 42)\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use tensorflow index notation, keep as 2D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many data sets use X[m,nh,nw,nc] and tesnsorflow and scikits learn use m as first index\n",
    "# keep this convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data input and formatted properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start up tensorboard with \n",
    "$ tensorboard --logdir=./tmp/example --port=8002 --reload_interval=5\n",
    "\n",
    "open browser at http://localhost:8002/ \n",
    "then you should be able to see the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard log file path\n",
    "logs_path = './tmp/example3/'+datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset everything\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1)\n",
    "seed = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow constants, variables, placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, nh, nw, nc], name=\"X\")\n",
    "    y_true = tf.placeholder(tf.float32, shape=[None, n_classes], name=\"y_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('filterWeights'):\n",
    "    W1 = tf.get_variable(\"W1\", [4, 4, nc, 8], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "# tensorflow's fully-connected function used here initializes its own weights automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('convLayer1'):\n",
    "    z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
    "    a1 = tf.nn.relu(z1)\n",
    "    p1 = tf.nn.max_pool(a1, ksize=[1,8,8,1], strides=[1,8,8,1], padding='SAME')\n",
    "with tf.name_scope('convLayer2'):\n",
    "    z2 = tf.nn.conv2d(p1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "    a2 = tf.nn.relu(z2)\n",
    "    p2 = tf.nn.max_pool(a2, ksize=[1,4,4,1], strides=[1,4,4,1], padding='SAME')\n",
    "with tf.name_scope('fullyConnected'):\n",
    "    p2 = tf.contrib.layers.flatten(p2)\n",
    "    z3 = tf.contrib.layers.fully_connected(p2, n_classes, activation_fn=None)\n",
    "with tf.name_scope('softmax'):\n",
    "    y  = tf.nn.softmax(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y)))\n",
    "\n",
    "# this cross-entropy function does softmax automatically\n",
    "# with tf.name_scope('cross_entropy'):\n",
    "#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, \\\n",
    "#                                                                      logits=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_predictions = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))   \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for tensorboard\n",
    "train_cost_summary = tf.summary.scalar(\"train_cost\", cost)\n",
    "train_accuracy_summary = tf.summary.scalar(\"train_accuracy\", accuracy)\n",
    "\n",
    "test_cost_summary = tf.summary.scalar(\"test_cost\", cost)\n",
    "test_accuracy_summary = tf.summary.scalar(\"test_accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mini_batches:  628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78db16772cd4dbd8b869ee9f23de831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=10, style=ProgressStyle(description_width='initiaâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Accuracy: 0.771212100982666\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # tensorboard log file writer    \n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    batch_count = np.int(num_examples/batch_size)\n",
    "    print ('number of mini_batches: ',batch_count)\n",
    "\n",
    "    for epoch in tnrange(training_epochs, desc='epoch'):\n",
    "        \n",
    "        seed = seed+1\n",
    "        mini_batches = random_mini_batches_img(X_train, y_train, batch_size, seed=seed)\n",
    "        \n",
    "        iter = 0        \n",
    "        for mini_batch in mini_batches:\n",
    "            \n",
    "            iter = iter+1\n",
    "\n",
    "            (batch_x, batch_y) = mini_batch\n",
    "            \n",
    "            _, train_cost, train_accuracy, _train_cost_summary, _train_accuracy_summary = \\\n",
    "               sess.run([train, cost, accuracy, train_cost_summary, train_accuracy_summary], \\\n",
    "                   feed_dict={X: batch_x, y_true: batch_y})\n",
    "            \n",
    "            writer.add_summary(_train_cost_summary, epoch * batch_count + iter)\n",
    "            writer.add_summary(_train_accuracy_summary, epoch * batch_count + iter)\n",
    "       \n",
    "            if iter % 100 == 0:\n",
    "                # for log on test data:\n",
    "                test_cost, test_accuracy, _test_cost_summary, _test_accuracy_summary = \\\n",
    "                    sess.run([cost, accuracy, test_cost_summary, test_accuracy_summary], \\\n",
    "                        feed_dict={X:X_test, y_true:y_test})\n",
    "                # write log\n",
    "                writer.add_summary(_test_cost_summary, epoch * batch_count + iter)\n",
    "                writer.add_summary(_test_accuracy_summary, epoch * batch_count + iter)\n",
    "                \n",
    "#                 print('Epoch {0:3d}, Batch {1:3d} | Train Cost: {2:.2f} | Test Cost: {3:.2f} | Train Accuracy: {4:.2f} | Test Accuracy: {5:.2f}'.format(epoch, iter, train_cost, test_cost, train_accuracy, test_accuracy))\n",
    "            \n",
    "    print('Final Test Set Accuracy: {}'.format(accuracy.eval(feed_dict={X:X_test, y_true:y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
